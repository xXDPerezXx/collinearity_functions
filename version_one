import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import mutual_info_classif, mutual_info_regression
from sklearn.preprocessing import KBinsDiscretizer

def calculate_mutual_info(X, y, categorical_features, numeric_features):
    """
    Calculate mutual information between features and with target variable.
    """
    # Initialize an empty matrix to store the mutual information scores
    n_features = X.shape[1]
    mi_matrix = np.zeros((n_features, n_features))
    feature_names = list(X.columns)
    
    # Convert DataFrame to numpy array for consistent indexing
    X_array = X.values
    
    # Calculate the mutual information scores between each pair of features
    for i in range(n_features):
        for j in range(n_features):
            if i == j:
                mi_matrix[i, j] = 1.0
            elif i in categorical_features and j in categorical_features:
                mi_matrix[i, j] = mutual_info_classif(
                    X_array[:, i].reshape(-1, 1), 
                    X_array[:, j]
                )[0]
            elif i in numeric_features and j in numeric_features:
                mi_matrix[i, j] = mutual_info_regression(
                    X_array[:, i].reshape(-1, 1), 
                    X_array[:, j]
                )[0]
            elif i in categorical_features and j in numeric_features:
                est = KBinsDiscretizer(n_bins=5, encode='ordinal')
                X_discretized = est.fit_transform(X_array[:, j].reshape(-1, 1))
                mi_matrix[i, j] = mutual_info_classif(
                    X_array[:, i].reshape(-1, 1), 
                    X_discretized.ravel()
                )[0]
            elif i in numeric_features and j in categorical_features:
                est = KBinsDiscretizer(n_bins=5, encode='ordinal')
                X_discretized = est.fit_transform(X_array[:, i].reshape(-1, 1))
                mi_matrix[i, j] = mutual_info_classif(
                    X_discretized, 
                    X_array[:, j]
                )[0]
    
    # Create a DataFrame with the mutual information scores
    mi_df = pd.DataFrame(mi_matrix, index=feature_names, columns=feature_names)
    
    # Create the visualization
    fig, ax = plt.subplots(figsize=(12, 10))
    
    # Create heatmap
    im = ax.imshow(mi_df, cmap='coolwarm', aspect='auto')
    
    # Add colorbar
    cbar = ax.figure.colorbar(im, ax=ax)
    cbar.ax.set_ylabel('Mutual Information Score', rotation=-90, va="bottom")
    
    # Show all ticks and label them
    ax.set_xticks(np.arange(len(feature_names)))
    ax.set_yticks(np.arange(len(feature_names)))
    ax.set_xticklabels(feature_names)
    ax.set_yticklabels(feature_names)
    
    # Rotate the tick labels and set their alignment
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")
    
    # Loop over data dimensions and create text annotations
    for i in range(len(feature_names)):
        for j in range(len(feature_names)):
            text = ax.text(j, i, f'{mi_df.iloc[i, j]:.2f}',
                         ha="center", va="center", color="black")
    
    # Add title
    ax.set_title("Mutual Information Matrix")
    
    # Tight layout to prevent label cutoff
    fig.tight_layout()
    
    plt.show()
    
    # Calculate feature importances
    feature_importances = []
    for i in range(n_features):
        if i in categorical_features:
            mi_score = mutual_info_classif(
                X_array[:, i].reshape(-1, 1), 
                y
            )[0]
        else:
            mi_score = mutual_info_regression(
                X_array[:, i].reshape(-1, 1), 
                y
            )[0]
        feature_importances.append((feature_names[i], mi_score))
    
    feature_importances.sort(key=lambda x: x[1], reverse=True)
    feature_importances_df = pd.DataFrame(
        feature_importances, 
        columns=['Feature', 'Importance']
    )
    
    return mi_df, feature_importances_df

# Example usage:
if __name__ == "__main__":
    from sklearn.datasets import load_iris
    iris = load_iris()
    X = pd.DataFrame(iris.data, columns=iris.feature_names)
    y = iris.target
    categorical_features = []
    numeric_features = list(range(X.shape[1]))
    mi_df, feature_importances_df = calculate_mutual_info(
        X, y, categorical_features, numeric_features
    )
    print("\nMutual Information Matrix:")
    print(mi_df)
    print("\nFeature Importances:")
    print(feature_importances_df)
